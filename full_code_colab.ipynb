{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1.multiple-choice-gpt2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVb_7oRx3AnP"
      },
      "source": [
        "pip install transformers &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMOwtdP74As4"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PfKUeFEj4E8D"
      },
      "source": [
        "model_name = 'gpt2-medium'\r\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\r\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X5hgMcGa-MWu"
      },
      "source": [
        "import numpy as np\r\n",
        "def score(sentence):\r\n",
        "    tokens_tensor = tokenizer(sentence, return_tensors=\"pt\")\r\n",
        "    loss = model(**tokens_tensor, labels=tokens_tensor['input_ids'])[0]\r\n",
        "    # Use detach().numpy().item() to convert tensor to float \r\n",
        "    return loss.detach().numpy().item() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GwFjlOrb-bv-"
      },
      "source": [
        "def use_gpt2(question,options):\r\n",
        "  scores = [score(question.replace(\"[MASK]\", o)) for o in options]\r\n",
        "  # # Uncomment this code to print score of each option\r\n",
        "  # for i in zip(options,scores):\r\n",
        "  #   print(i)\r\n",
        "  return options[np.argmin(scores)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HV5YuQ9X-o9x"
      },
      "source": [
        "def compare(results, answers):\r\n",
        "  correct = 0 \r\n",
        "  for i in range(len(results)):\r\n",
        "    if results[i] == answers[i]:\r\n",
        "      correct += 1\r\n",
        "    # # Uncomment this code to print wrong answer \r\n",
        "    # else:\r\n",
        "    #   print(i)\r\n",
        "    #   print(results[i])\r\n",
        "    #   print(answers[i])\r\n",
        "  return correct/len(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4UKwLtv77u3P"
      },
      "source": [
        "import urllib.request, json \r\n",
        "def read_json(path):\r\n",
        "  with urllib.request.urlopen(path) as url:\r\n",
        "    data = json.loads(url.read().decode())\r\n",
        "  questions = []\r\n",
        "  answers = []\r\n",
        "  options = []\r\n",
        "  for d in data.values():\r\n",
        "    questions.append(d['question'])\r\n",
        "    answers.append(d['anwser'])\r\n",
        "    option = [d[str(i)] for i in range(1,5)]\r\n",
        "    options.append(option)\r\n",
        "  return questions, answers, options"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwK_whkW7xFh"
      },
      "source": [
        "# Use this code to get words filling dataset\r\n",
        "questions, answers, options = read_json(\"https://raw.githubusercontent.com/tranganhthuan/TOEIC_Mask_Filling/main/data/words_filling.json\")\r\n",
        "\r\n",
        "# # Use this code to get sentence filling dataset\r\n",
        "# questions, answers, options = read_json(\"https://raw.githubusercontent.com/tranganhthuan/TOEIC_Mask_Filling/main/data/sentence_filling.json\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqXZdtaP-u9G"
      },
      "source": [
        "# Use this code to calculate result only\r\n",
        "results = [use_gpt2(q,o) for (q,o) in zip(questions, options)]\r\n",
        "\r\n",
        "# # Use this code to print the loop\r\n",
        "# i = 0\r\n",
        "# results = []\r\n",
        "# for q,o in zip(questions, options):\r\n",
        "#   print(i)\r\n",
        "#   results.append(use_gpt2(q,o))\r\n",
        "#   i += 1"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMepki8CDsoa",
        "outputId": "1f839186-13b3-47db-9305-3410f7af0945"
      },
      "source": [
        "compare(results, answers)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}